{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from autowebcompat import network, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-n', '--network', type=str, choices=network.SUPPORTED_NETWORKS, help='Select the network to use for training')\n",
    "parser.add_argument('-o', '--optimizer', type=str, choices=network.SUPPORTED_OPTIMIZERS, help='Select the optimizer to use for training')\n",
    "parser.add_argument('-ct', '--classification_type', type=str, choices=utils.CLASSIFICATION_TYPES, default=utils.CLASSIFICATION_TYPES[0], help='Select the classification_type for training')\n",
    "parser.add_argument('-es', '--early_stopping', dest='early_stopping', action='store_true', help='Stop training training when validation accuracy has stopped improving.')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = utils.read_labels()\n",
    "\n",
    "utils.prepare_images()\n",
    "all_image_names = [i for i in utils.get_images() if i in labels]\n",
    "all_images = sum([[i + '_firefox.png', i + '_chrome.png'] for i in all_image_names], [])\n",
    "image = utils.load_image(all_images[0])\n",
    "input_shape = image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = len(all_image_names)\n",
    "TRAIN_SAMPLE = 80 * (SAMPLE_SIZE // 100)\n",
    "VALIDATION_SAMPLE = 10 * (SAMPLE_SIZE // 100)\n",
    "TEST_SAMPLE = SAMPLE_SIZE - (TRAIN_SAMPLE + VALIDATION_SAMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pair(fname):\n",
    "    return [fname + '_firefox.png', fname + '_chrome.png']\n",
    "\n",
    "\n",
    "random.shuffle(all_image_names)\n",
    "images_train, images_validation, images_test = all_image_names[:TRAIN_SAMPLE], all_image_names[TRAIN_SAMPLE:VALIDATION_SAMPLE + TRAIN_SAMPLE], all_image_names[SAMPLE_SIZE - TEST_SAMPLE:]\n",
    "\n",
    "\n",
    "def couples_generator(images):\n",
    "    for i in images:\n",
    "        yield load_pair(i), utils.to_categorical_label(labels[i], args.classification_type)\n",
    "\n",
    "\n",
    "def gen_func(images):\n",
    "    return couples_generator(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_couples_len = sum(1 for e in gen_func(images_train))\n",
    "validation_couples_len = sum(1 for e in gen_func(images_validation))\n",
    "test_couples_len = sum(1 for e in gen_func(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_gen = utils.get_ImageDataGenerator(all_images, input_shape)\n",
    "train_iterator = utils.CouplesIterator(utils.make_infinite(gen_func, images_train), input_shape, data_gen, BATCH_SIZE)\n",
    "validation_iterator = utils.CouplesIterator(utils.make_infinite(gen_func, images_validation), input_shape, data_gen, BATCH_SIZE)\n",
    "test_iterator = utils.CouplesIterator(utils.make_infinite(gen_func, images_test), input_shape, data_gen, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.create(input_shape, args.network)\n",
    "network.compile(model, args.optimizer)\n",
    "\n",
    "callbacks_list = [ModelCheckpoint('best_train_model.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')]\n",
    "\n",
    "if args.early_stopping:\n",
    "    callbacks_list.append(EarlyStopping(monitor='val_accuracy', patience=2))\n",
    "\n",
    "model.fit_generator(train_iterator, callbacks=callbacks_list, validation_data=validation_iterator, steps_per_epoch=train_couples_len / BATCH_SIZE, validation_steps=validation_couples_len / BATCH_SIZE, epochs=EPOCHS)\n",
    "score = model.evaluate_generator(test_iterator, steps=test_couples_len / BATCH_SIZE)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
